{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda0,force_device=True,floatX=float32,gpuarray.preallocate=0.3\"\n",
    "import theano\n",
    "print(theano.config.device)\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Layer, merge, Input, Concatenate, Reshape, concatenate,Lambda,multiply,Permute,Reshape,RepeatVector\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the ChIP-seq data used in this work in <http://deepsea.princeton.edu/media/code/deepsea_train_bundle.v0.9.tar.gz>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ater unzipping the 'deepsea_train_bundle.v0.9.tar.gz' file, locate the 'train.mat', 'valid.mat' and 'test.mat' files in the 'deepsea_train' folder into the './data' folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data (training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"./data/\"\n",
    "\n",
    "trainmat = h5py.File(data_folder+'train.mat')\n",
    "validmat = scipy.io.loadmat(data_folder+'valid.mat')\n",
    "\n",
    "X_train = np.transpose(np.array(trainmat['trainxdata']),axes=(2,0,1))\n",
    "y_train = np.array(trainmat['traindata']).T\n",
    "\n",
    "trainmat.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose only the targets that correspond to the TF binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:,125:815]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CLARINET\n",
    "CLARINET is built upon keras implementation of DanQ*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Quang, Daniel, and Xiaohui Xie. \"DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences.\" Nucleic acids research 44.11 (2016): e107-e107."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model\n",
      "running at most 60 epochs\n",
      "model summary\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 1000, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 993, 64)      2112        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 989, 64)      3136        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 985, 64)      4160        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 981, 64)      5184        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 977, 64)      6208        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 76, 64)       0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 76, 64)       0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 75, 64)       0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 75, 64)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 75, 64)       0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 75, 64)       0           max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 75, 64)       0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 75, 64)       0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 75, 64)       0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 75, 64)       0           max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 75, 320)      0           lambda_21[0][0]                  \n",
      "                                                                 lambda_22[0][0]                  \n",
      "                                                                 lambda_23[0][0]                  \n",
      "                                                                 lambda_24[0][0]                  \n",
      "                                                                 lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 75, 320)      0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 75, 640)      1640960     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 75, 640)      0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 75, 100)      64100       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 100, 75)      0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 100, 75)      0           permute_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_5 (Permute)             (None, 75, 100)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attention (Lambda)              (None, 75)           0           permute_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_4 (RepeatVector)  (None, 640, 75)      0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_6 (Permute)             (None, 75, 640)      0           repeat_vector_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 75, 640)      0           dropout_10[0][0]                 \n",
      "                                                                 permute_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 48000)        0           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 695)          33360695    flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 695)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 690)          480240      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 690)          0           dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 35,566,795\n",
      "Trainable params: 35,566,795\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 4400000 samples, validate on 8000 samples\n",
      "Epoch 1/60\n",
      "4400000/4400000 [==============================] - 26769s 6ms/step - loss: 0.0397 - val_loss: 0.0308\n",
      "\n",
      "Epoch 00001: saving model to ./CLARINET_Final_k100.01-0.03.hdf5\n",
      "Epoch 2/60\n",
      "4400000/4400000 [==============================] - 25855s 6ms/step - loss: 0.0345 - val_loss: 0.0282\n",
      "\n",
      "Epoch 00002: saving model to ./CLARINET_Final_k100.02-0.03.hdf5\n",
      "Epoch 3/60\n",
      "4400000/4400000 [==============================] - 25851s 6ms/step - loss: 0.0328 - val_loss: 0.0278\n",
      "\n",
      "Epoch 00003: saving model to ./CLARINET_Final_k100.03-0.03.hdf5\n",
      "Epoch 4/60\n",
      "4400000/4400000 [==============================] - 26088s 6ms/step - loss: 0.0320 - val_loss: 0.0273\n",
      "\n",
      "Epoch 00004: saving model to ./CLARINET_Final_k100.04-0.03.hdf5\n",
      "Epoch 5/60\n",
      "4400000/4400000 [==============================] - 25415s 6ms/step - loss: 0.0315 - val_loss: 0.0273\n",
      "\n",
      "Epoch 00005: saving model to ./CLARINET_Final_k100.05-0.03.hdf5\n",
      "Epoch 6/60\n",
      "  82300/4400000 [..............................] - ETA: 6:52:49 - loss: 0.0304"
     ]
    }
   ],
   "source": [
    "kernel_sizes = [8,12,16,20,24]\n",
    "kernel_nums = [64,64,64,64,64]\n",
    "kernel_parms = list(zip(kernel_sizes,kernel_nums))\n",
    "\n",
    "sequence_input = Input(shape=(1000,4))\n",
    "\n",
    "#CNN layer\n",
    "conv_outputs =[]\n",
    "for kernel_size, kernel_num in kernel_parms:\n",
    "    conv_output = Conv1D(kernel_num,kernel_size=kernel_size,padding=\"valid\",activation=\"relu\")(sequence_input)\n",
    "\n",
    "\n",
    "    conv_output = MaxPooling1D(pool_size=13, strides=13)(conv_output)\n",
    "    conv_output = Lambda(lambda x : x[:,:75,:],output_shape=(75, 64))(conv_output)\n",
    "    conv_outputs.append(conv_output)\n",
    "output = Concatenate()(conv_outputs)\n",
    "output = Dropout(0.2)(output)\n",
    "\n",
    "#BiLSTM layer\n",
    "output = Bidirectional(LSTM(320,return_sequences=True))(output)\n",
    "output = Dropout(0.5)(output)\n",
    "\n",
    "\n",
    "# Attention layer\n",
    "p = 100\n",
    "attention = Dense(p)(output)\n",
    "attention = Permute((2, 1))(attention)\n",
    "attention = Activation('softmax')(attention)\n",
    "attention = Permute((2, 1))(attention)\n",
    "attention = Lambda(lambda x: K.mean(x, axis=2), name='attention',output_shape=(75,))(attention)\n",
    "attention = RepeatVector(640)(attention)\n",
    "attention = Permute((2,1))(attention)\n",
    "\n",
    "output = multiply([output, attention])\n",
    "\n",
    "#Fully connected layer\n",
    "output = Flatten()(output)\n",
    "\n",
    "output = Dense(695)(output)\n",
    "output = Activation('relu')(output)\n",
    "\n",
    "#Output layer\n",
    "output = Dense(690)(output)\n",
    "output = Activation('sigmoid')(output)\n",
    "\n",
    "model = Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "print('compiling model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "print('running at most 60 epochs')\n",
    "\n",
    "print('model summary')\n",
    "model.summary()\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"./models/CLARINET_.{epoch:02d}-{val_loss:.2f}.hdf5\", verbose=1, save_best_only=False)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=100, epochs=60, shuffle=True, verbose=1, validation_data=(np.transpose(validmat['validxdata'],axes=(0,2,1)),validmat['validdata'][:,125:815]), callbacks=[checkpointer,earlystopper])\n",
    "\n",
    "\n",
    "model.save('./models/CLARINET.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
