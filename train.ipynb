{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda0,force_device=True,floatX=float32,gpuarray.preallocate=0.3\"\n",
    "import theano\n",
    "print(theano.config.device)\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Layer, merge, Input, Concatenate, Reshape, concatenate,Lambda,multiply,Permute,Reshape,RepeatVector\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the ChIP-seq data used in this work in <http://deepsea.princeton.edu/media/code/deepsea_train_bundle.v0.9.tar.gz>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ater unzipping the 'deepsea_train_bundle.v0.9.tar.gz' file, place the 'train.mat', 'valid.mat' and 'test.mat' files in the 'deepsea_train' folder into the './data' folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data (training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"./data/\"\n",
    "\n",
    "trainmat = h5py.File(data_folder+'train.mat')\n",
    "validmat = scipy.io.loadmat(data_folder+'valid.mat')\n",
    "\n",
    "X_train = np.transpose(np.array(trainmat['trainxdata']),axes=(2,0,1))\n",
    "y_train = np.array(trainmat['traindata']).T\n",
    "\n",
    "trainmat.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose only the targets that correspond to the TF binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:,125:815]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CLARINET"
   ]
  },  
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes = [8,12,16,20,24]\n",
    "kernel_nums = [64,64,64,64,64]\n",
    "kernel_parms = list(zip(kernel_sizes,kernel_nums))\n",
    "\n",
    "sequence_input = Input(shape=(1000,4))\n",
    "\n",
    "#CNN layer\n",
    "conv_outputs =[]\n",
    "for kernel_size, kernel_num in kernel_parms:\n",
    "    conv_output = Conv1D(kernel_num,kernel_size=kernel_size,padding=\"valid\",activation=\"relu\")(sequence_input)\n",
    "\n",
    "\n",
    "    conv_output = MaxPooling1D(pool_size=13, strides=13)(conv_output)\n",
    "    conv_output = Lambda(lambda x : x[:,:75,:],output_shape=(75, 64))(conv_output)\n",
    "    conv_outputs.append(conv_output)\n",
    "output = Concatenate()(conv_outputs)\n",
    "output = Dropout(0.2)(output)\n",
    "\n",
    "#BiLSTM layer\n",
    "output = Bidirectional(LSTM(320,return_sequences=True))(output)\n",
    "output = Dropout(0.5)(output)\n",
    "\n",
    "\n",
    "# Attention layer\n",
    "p = 100\n",
    "attention = Dense(p)(output)\n",
    "attention = Permute((2, 1))(attention)\n",
    "attention = Activation('softmax')(attention)\n",
    "attention = Permute((2, 1))(attention)\n",
    "attention = Lambda(lambda x: K.mean(x, axis=2), name='attention',output_shape=(75,))(attention)\n",
    "attention = RepeatVector(640)(attention)\n",
    "attention = Permute((2,1))(attention)\n",
    "\n",
    "output = multiply([output, attention])\n",
    "\n",
    "#Fully connected layer\n",
    "output = Flatten()(output)\n",
    "\n",
    "output = Dense(695)(output)\n",
    "output = Activation('relu')(output)\n",
    "\n",
    "#Output layer\n",
    "output = Dense(690)(output)\n",
    "output = Activation('sigmoid')(output)\n",
    "\n",
    "model = Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "print('compiling model')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "print('running at most 60 epochs')\n",
    "\n",
    "print('model summary')\n",
    "model.summary()\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"./models/CLARINET_.{epoch:02d}-{val_loss:.2f}.hdf5\", verbose=1, save_best_only=False)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=100, epochs=60, shuffle=True, verbose=1, validation_data=(np.transpose(validmat['validxdata'],axes=(0,2,1)),validmat['validdata'][:,125:815]), callbacks=[checkpointer,earlystopper])\n",
    "\n",
    "\n",
    "model.save('./models/CLARINET.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
